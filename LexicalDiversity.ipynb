{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e072555-28a7-4d96-8c52-c85e23a8ecb5",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730c382b-abc3-43c6-9ffb-133b1f2a7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96e386-19b7-4327-8b30-c95ee163179f",
   "metadata": {},
   "source": [
    "#### Load stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "997357da-cfcb-4028-a43f-3af6c7a534e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'NewYorkerStories.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    stories = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6511bc06-ad3c-4317-a27c-bf960d1f3c69",
   "metadata": {},
   "source": [
    "#### Function to calculate Lexical diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ff09b6-9c68-4f3d-aa44-6bc5fe4fe8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    words = text.split() \n",
    "    return len(set(words)) / len(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed189b-2a72-42d4-9aa1-c516511cd98b",
   "metadata": {},
   "source": [
    "#### Function to calculate unexpected score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edcb43ec-e576-424c-812a-8658b1ac3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "all_words = []\n",
    "for story in stories:\n",
    "    all_words.extend(story['content'].split())\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "def unexpected_score(text):\n",
    "    words = text.split()\n",
    "    return sum(1 / (1 + word_counts[w]) for w in words) / len(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce6d82-6d70-4a1e-9879-86e34d79d436",
   "metadata": {},
   "source": [
    "#### Calculate for each story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920514aa-181a-4131-8e92-7e02ada09ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()\n",
    "for story in stories:\n",
    "    lex = lexical_diversity(story['content'])\n",
    "    unex = unexpected_score(story['content'])\n",
    "    new_row = pd.DataFrame([{\"story\": story['story_id'].split(\"_\",1)[0], \"writer\": story['story_id'].split(\"_\",1)[1], \"lex\":lex, \"unex\":unex}])\n",
    "    scores = pd.concat([scores, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc663f8-f213-4b3f-afac-1d1e975d13bc",
   "metadata": {},
   "source": [
    "#### Save scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db2c172-db8d-464a-8007-5d12b7ca6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv('lex_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda (dis)",
   "language": "python",
   "name": "dis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
